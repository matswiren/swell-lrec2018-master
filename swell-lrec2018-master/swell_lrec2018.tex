\documentclass[10pt, a4paper]{article}
\usepackage{lrec}
\usepackage{multibib}
\newcites{languageresource}{Language Resources}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{soul}
\usepackage{color}
% for eps graphics

\usepackage{verbatim} % comment environment

\usepackage[normalem]{ulem} % overstrike \sout{..}

\usepackage{epstopdf}
\usepackage[utf8]{inputenc}

\usepackage{hyperref}
\usepackage{xstring}

\usepackage[dvipsnames]{xcolor}

\newcommand{\secref}[1]{\StrSubstitute{\getrefnumber{#1}}{.}{ }}

\newcommand{\dan}[1]{{\color{Fuchsia}{Dan: #1}}}

\newcommand{\elena}[1]{{\color{BrickRed}{Elena: #1}}}

\title{Towards Transformation-based Annotation of Norm Deviations \\ in an Infrastructure for Research on Swedish as a Second Language}

%\title{Transformation-based Annotation of Norm Deviations \\ in an Infrastructure for Research on Swedish as a Second Language}

\name{Dan Rosén\textsuperscript{1},
      Mats Wirén\textsuperscript{2},
      Elena Volodina\textsuperscript{1}}

\address{\textsuperscript{1}Språkbanken, University of Gothenburg, \textsuperscript{2}Stockholm University \\
         \textsuperscript{1}Box 200, 40530 Göteborg, \textsuperscript{2}SE-10691 Stockholm \\
         dan.rosen@svenska.gu.se, mats.wiren@ling.su.se, elena.volodina@svenska.gu.se\\
%         \{author1, author5, author9\}@abc.org\\
         }

\abstract{
This paper describes ongoing work on a system for annotation of norm deviations (errors) in second-language learner texts, a key component in an intended infrastructure for research on Swedish as a second language. Unlike traditional approaches which treat this as a single task applied to a static learner text, our approach is divided into two steps to reflect the conceptual structure of the problem: a) normalisation  of the learner text by transforming (editing) it to reflect the target hypotheses, and b) the actual norm-deviation annotation, supported by visualisation of the differences between source and normalisation. Another distinct feature of our approach is that a parallel text is generated in the transformation step, with word alignments inferred from the editing operations. This parallel text is a useful resource in its own right, by allowing for search in either or both of the source and normalised texts, and for training of systems for automated annotation of norm deviations. We describe the existing system for normalisation and outline the associated system for annotation of norm deviations currently being implemented, as well as the overall intended workflow. %[185 words out of 200 allowed]
}

\begin{document}

\maketitleabstract

\section{Background and Introduction}

This work is carried out within the SweLL project, whose goal is to construct an electronic research infrastructure for Swedish as a second language. We take an electronic research infrastructure to consist of the following components: \elena{maybe we can shorten this list?}
\begin{enumerate}
\item freely accessible data in electronic format;
\item a set of tools for data collection and processing, including 
analysis of proficiency levels, norm-deviation (error) annotation, and linguistic annotation;
\item a technical platform for exploring the data with tools for data analysis and visualization;
\item expertise within the relevant areas.
\end{enumerate}

The need for data is omnipresent within language technology projects, not the least when it comes to data produced by second language (L2) learners. Not only is the L2 data sensitive in nature and requires (agreements for use of) associated socio-demographic information, but it also demonstrates significant deviations from the norms that standard tools for natural-language processing (NLP) are tailored for. Preparation of L2 data for NLP experiments as well as for effective Second Language Acquisition (SLA) research analysis is therefore very demanding, and annotation of norm deviations (i.e. errors) is arguably the most time-consuming step.

We focus here on the tool for annotation of norm deviations in learner texts as one of the necessary components of the SweLL infrastructure. We introduce the term \textit{norm deviation} in an attempt to step away from the term "error" which is predominantly critical towards learner interlanguage \cite{Selinker1972}, i.e. the developing language system learners create in their minds on the way towards the target language. Connected to this, we use the term \textit{normalization}, that in this context is understood as modification of a learner text to reflect the norms of the target language. 

In this paper we develop the idea of \textit{transformation-based normalization} of learner texts as a primary step in annotation of norm deviations. The origins of the term go to a predecessing pilot within SweLL project \cite{correctAnnotator}, where the idea of logging user actions while editing learner essays was suggested, which in turn has been inspired by the Arabic tool QAWI \cite{QAWI}. We argue that this method is user-friendly and is effective in optimizing manual annotation process through prompting the annotation of norm deviations by comparing original and normalized versions of the same text.

The rest of the paper is structured as follows: in the next section we set the development of our tool into the context of other available tools for annotation of norm deviations. Motivation behind  transformation-based approach to text normalization is provided in section \ref{sec:targethypothesis} The design of the tool (its prototype) is described in section \ref{sec:norm_tool}, followed by the principles for annotation of norm deviations in section \ref{sec:ann_tool} We conclude the paper with discussion and conclusions.

\section{Related work}
\label{sec:relatedwork}

(Manual) annotation of data for various Language Technology and Digital Humanities projects is a recurring task, which has resulted in a huge number of tools that support annotation of data. Some of the tools are tailored to a particular project need (REFs), others are more generic (REFs). Some drawbacks of generic annotators, e.g. WebAnno (REF) or BRAT (REF) consist in their 
...tricky annotation process; annotations are not structurable and not recyclable; no annotation statistics; no options to perform searches on annotations themselves

Reusing project-specific tools for other - similar - projects may entail problems with data formats and lacking (bidirectional) interoperability between the tools, undermining effectiveness of their use \elena{, as for example, was the case in MERLIN project with reuse of PAULA, Exmaralda, and FALKO excel plugin\footnote{Information obtained through personal communication with Merlin collaborators and access to their analysis of the used technology, documented in the "Black Book"} (REFS; REFS; REFS)}. 

On the other hand, tools developed for seemingly unrelated areas, for example for annotation parallel corpora (e.g. REF), can provide a number of solutions and insights - especially, if L2 corpora are viewed as two parallel versions: original one, that is, written by the learner, and normalized one, that is, a version of the same text with expert introduced corrections.

A number of existing frameworks for annotation, such as XXX, offer a possibility to build on top of them and adjust to the project aims.

%Related work: various tools in Merlin, exmaralda, Johannes Gräen (multilingual parallel corpus, initial project on Europarl), BRAT (label tokens and draw dependency trees) (http://brat.nlplab.org/index.html) / opensource framework BRAT (Stenetorp et al., 2012)- annotation schemes can be defined for various purposes, including essay marking (Cf. Kutuzov & Kuzmenko, 2015), , webanno (a layer on top of BRAT), annotateit.org, diigo.com,Sacodeyl (http://www.um.es/sacodeyl/en/pages/software.htm);

% (for an overview of error annotation schemes and their implementation, see Lüdeling and Hirschmann, 2015,

Annotation of norm deviations in second-language learner texts (traditionally
called error annotation) is typically done with a purpose-built editing tool,
using a hierarchical set of error categories (Granger 2009). For example,
in ASK (Tenfjord et al. 2006), the editor used is the XML editor Oxygen,
% I don't think we need to refer to this editor?
% \footnote{\url{https://www.oxygenxml.com}},
customised with pop-up menus that reflect the chosen set of error
categories. Specifically, annotation of an error involves inserting an XML
{\em sic} tag with a {\em type} attribute encoding the error category, a {\em
desc} attribute endoding the error subcategory, and a {\em corr} attribute
encoding the correct (normalised) form of the token or tokens.
While editing the XML file it is translated to a presentation format in HTML
which can be viewed in a web browser, thereby facilitating proofreading of
the annotation.

The basic problem with this kind of approach is that it conflates the conceptually separate stages of (traditionally speaking) error coding, namely, error detection, correction and annotation (Corder 1974, Ellis 1994, Granger 2009, page 266). This is because correction (normalisation, based on a target hypothesis) is carried out as a subtask of error annotation instead of as an independent task, prior to and separate from error annotation. Also, since normalisations are only a by-product of error annotations, the corrected text as a whole is not readily available for inspection after each annotation step, and it may therefore be more cumbersome to produce a consistent normalisation.

In Falko \cite{ludeling05multi-levelerror} and MERLIN  \cite{MERLIN2014},
target hypothesis corrections have a more independent status in the sense that they are entered in a separate step prior to error annotation, but the normalised text still does not seem to be available in its entirety.

To circumvent these problems, our approach is based on dividing error coding into two steps: normalising the text by transforming (editing) it into a corrected form according to some criteria, and annotating the norm deviations corresponding to the changes.



A bit about traditional tools like   (BRAT, etc..)

\section{Target Hypotheses and Editing}
\label{sec:targethypothesis}

\dan{Highlight that the produced resource is actually a parallel corpus?}

Normalisation involves, for each deviation from the norm, to decide on a target hypothesis and to edit the text to mirror this hypothesis. We allow edit operations of characters and tokens, involving insertions, deletions, substitutions % \textcolor{red}{EV:("substitution" instead of "replacement"?; merge? split? - separate actions or as variants of replacement, insertion and deletion?)} and move \textcolor{red}{EV:(Is it a term?)}
or moves (see Section~\ref{sec:norm_tool}). By keeping track of the sequence of edit operations, an additional advantage could be gained, namely, that a preliminary error annotation can be automatically inferred (see Section~\ref{sec:ann_tool}). This is something that we plan to explore later on in the project.

It might be argued that insertions, deletions and
replacements could be calculated automatically from the differences between the source and normalised texts without logging the edit operations, but moves of tokens (which we need in order to keep track of word-order changes) result in added complexity \cite{ShapiraStorer2007} and ambiguities, which is why we log the editing operations.

\begin{figure*}
\includegraphics[width=\textwidth, trim={0 1cm 0 0}, clip]{screenshot.pdf}
\emph{\small I live in an apartment. I have lived there for one year. I would like to have a big house.}
\caption{Screenshot of an editing session in progress. The three panes in the upper row are from left to right:
1) the source text which cannot be edited,
2) the target hypothesis which is where the annotator do all their edits,
3) a calculated view of the differences between the two texts obtained from the history of edits.
Below the panes we display the the differences pictorially:
the source text on top and the target hypothesis below, with edges
showing how words have been moved.
\dan{todo on Monday: experiment with other graphical layouts of the edges
so it doesn't look like {\em stor} and {\em hus} are connected etc}
% Deletions are shown in \textcolor{red}{red} with \sout{overstrike},
% insertions in \textcolor{green}{green} with \underline{underline}.
% (If the text is too long only the current sentence is shown.)
\label{fig:screenshot}
}
\end{figure*}

Some systems allow for multiple (vertical) levels of target hypotheses. In the Czech learner corpus of \newcite{Hana2012} a
first level normalises grammatical forms without context information. All other deviations (e.g.\ word order) belong to a second level and take the whole sentence into consideration.
In MERLIN \cite{MERLIN2014} two levels are used: a) minimal corrections pertaining only to orthographic and grammatical errors and b) corrections to handle sociolinguistic, lexical and pragmatic deviations to arrive at what is referred to as an acceptable text. This could be handled in our approach by maintaining several levels of aligned normalisations. The first level (with basic corrections) would then be aligned to the source text, and the second level (with additional corrections) would be aligned to the first level. Adding several levels is something that we have not undertaken yet, however.

We also do not handle multiple {\em competing} target hypotheses for the same source material in the manner of L{\"u}deling et al. (2005, Section 2.1).\footnote{An example of this from L{\"u}deling et al. (2005) is "diese Ph{\"a}nomen" which could be interpreted either as a gender error (with the target hypothesis "dieses Ph{\"a}nomen") or as a number error (with the target hypothesis "diese Ph{\"a}nomene").} In principle, this could be dealt with in our approach by maintaining different normalisations on the same level for a given part of the source text.

\section{Design of our normalisation tool}
\label{sec:norm_tool}
\dan{Should we name the tool?}

We set off to build a normalisation tool to be both simple and expressive.
We wanted it to have the feel of a conventional text editor and yet retain
information about how a word was normalised or where it was moved to.
\dan{Comment that we did not find any tool fulfilling our wishes/requirements?}

To facilitate normalisation and to support reliability and consistency,
we use four panes (see Figure~\ref{fig:screenshot}): one containing the
frozen source text, one in which the editing takes place, one in which
changes are highlighted, and finally one which shows links between tokens in the source text and normalised text.
% Where should this paragraph be?
We assume that during normalisation, the user can be required to pay attention
to how their edits affect the links between the source text and the target
hypothesis. We facilitate this by providing views of their difference and
the links between them.

To be
able to answer questions about movement we make the assumption that the text
can be tokenized. For now we assume that tokens are separated by whitespace
and cannot contain whitespace themselves. Thus inserting whitespace between
characters makes a new token and deleting the last whitespace between two
tokens merges them into one.

For expressing overcompounding and oversplitting we need links between tokens
that are many-to-one and one-to-many. We express insertion or deletion with
zero-to-one and one-to-zero links. We initially experimented with not allowing
many-to-many links but this asymmetry yielded no substantial benefits
and we now allow many-to-many links.
% of which we outline some benefits of below
For simplicity we require each component
of links must be complete: missing edges are automatically added by
transitivity.

We now outline how to instrument a traditional text editor to support links.
When starting the editing session the source and target are identical so the
links are initialised with the identity mapping. The user starts editing
by inserting and/or deleting characters.
We generalise this to each edit replacing the current selection with a
string. Usually the selection is just the cursor and the ``replacement'' string
is one character: then the modification is an insertion.
If the selection has non-zero width the user did an actual replacement.
Deletions are modelled by replacing with the empty string.
%The inserted string can also have length greater than one if the user pastes text into the editor.

When the editor is linked to a source text we also need to update the links.
This is how to resolve the possible editing situations:
% Could make images for each and every one of these (but what example texts to use?)

\dan{
Examples in ascii-art for now!
I intend to make proper (small) screenshots of these on Monday.
}

\begin{itemize}

\item {\it Edit within an existing token:}
Update the target word, links stay the same.
\begin{verbatim}
   snab|t
       |
       |
   snabb|t
\end{verbatim}
The cursor is indicated with \verb!|!. The user inserts \verb!b!.

\item {\it Edit ranging over several tokens:}
Merge the links from the involved tokens and update the text.
\begin{verbatim}
   person |nummer
       \   /
        \ /
         |
    personnummer
\end{verbatim}
The space between the word was removed.

\item {\it Edit removing a token completely:}
Removes any links from the source to this target token.
If this removes the last link of a source token it means that
it is deleted in the hypothesis (presumably a redundant word.)
\begin{verbatim}
    [De ]vädret var bra
      |    |     |   |
      x    |     |   |
           |     |   |
         vädret var bra
\end{verbatim}
Here the user has selected the word \verb!De ! and removed it
(by pressing either backspace or delete.)

\item {\it Edit introducing new whitespace:}
The user wants to split a word, perhaps an overcompound.
Pass over all links form the token to each new token.
\begin{verbatim}
    mycket|bra
         |
        / \
       /   \
    mycket |bra
\end{verbatim}
A space after \verb!mycket! was inserted.
\end{itemize}

Note that still missing is a way to introduce inserted words
unlinked to the source text. We support this by a special case of
inserting whitespace: if it makes two tokens where one is the source
token, we mark the other one as an insertion instead of a split. Example:

\begin{verbatim}
I)                II)
Jag gick stan     Jag gick     stan
 |    |   |        |    |       |
 |    |   |        |    |   .   |
 |    |   |        |    |   |   |
Jag gick på|stan  Jag gick på |stan
\end{verbatim}
The user first changes \verb!stan! to \verb!påstan!, which is still one token.
When the user inserts the space after \verb!på!, making \verb!på stan!, we do
not link both of these to the original \verb!stan!,
but instead break off \verb!på!.
However, if this is not the analysis the user wants the links to represent,
they undo this automatic behaviour by pressing {\it Ctrl-Z},
yielding this\footnote{\dan{Not yet in the interface, but the fix is minuscule.}}:

\begin{verbatim}
II)
Jag gick  stan
|    |     |
|    |    / \
|    |   |   |
Jag gick på |stan
\end{verbatim}

% Similarly, there is an automatic revert if you rewrite the text of split
% tokens into exaclty what they were
% but this is entirely straightforward and relatively uninteresting.

\paragraph{Word order normalisation as cut \& paste}
Viewing edits abstractly as replacing a selection with a string encompasses
edit operations, including derived operations such as search and replace,
which can be seen as a sequence of edits. However, cut \& paste needs to
be modified to work intuitively. We modify them in a way so they capture
word order normalisation by making them aware of the link structure.
So, to move a sequence of words the user selects a range
which includes these words and presses the shortcut for cutting: {\it Ctrl+X}.
This does not yet cut the words but instead highlights them. We expand partially
selected tokens to whole tokens to simplify this operation. The user then
navigates to the position they want the words to go and presses the paste
shortcut: {\it Ctrl+V}.
This moves the tokens together with their links to the new position.
This rearranging operation can also be executed with the mouse using drag and drop.
\dan{Intend to add image with example showing this step by step}

\subparagraph{Undo} We support unlimited chronological undo and redo operations.
For convenience we also support undo at a specific position. % in the hypothesis.
If this position is part of a compound of the entire compound is reverted. %EV: don't understand this sentence. One "of" is too much?
Tokens are rearranged into their original positions, which
can be recovered using unmoved words as reference points.
Undoing is very useful to get links exactly right, which occasionally takes a
few tries.
% Auto-revert: we automatically auto-revert compounds if the user writes them
% back to the original

\subparagraph{Intra-token diffs} We show differences inside tokens by
calculating a diff automatically using standard techniques for finding
edit scripts.  Deletions are shown in red with overstrike and insertions
in green.  Note that this intra-token diff is recalculated after every edit
as interntally only replacements on the token level are stored.  However,
this clear highlighting of differences works as an aid for the user.

\paragraph{Implementation}
We have implemented a working prototype as a single-page web application.
It does not rely on any server backend: all processing is done in the
client's browser. We use an off-the-shelf editor for the browser,
CodeMirror \cite{CodeMirror}.
Besides the CodeMirror's internal state, we keep an array of the tokens in the
target text together with links as indexes of tokens in the source,
and keep this in sync with the CodeMirror editor as described in this section.

The normalisation editor may also be used as a library and can in this way
be included in other tools and webpages.
\dan{Should we link to a demo version of the editor? Do LREC reviewers care
about running tools? It would be a good complement nevertheless.}
\dan{MIT License? This is what I have been supposing since it is the standard at SB}

% We only use immutable data
% structures for ease of implementation,  which could be an efficiency problem:
% it makes array operations linear in the number of tokens. Should
% this prove too slow for long texts it can be improved by restricting move
% operations, for example allowing them only within paragraphs. Alternatively,
% more sophisticated data structures could be used, such as ropes or sequences
% built on top of finger trees, which both admit updates in sublinear time.
% Could refer to Hinze's article
% I don't think anyone cares

\section{Annotation of Norm Deviations}
\label{sec:ann_tool}

We support annotating the edits from the normalisation with a taxonomy
of norm deviations.  The norm deviation annotations are put on the links:
on the entire connected component, like so \dan{in ascii art for now}:

\begin{verbatim}
person nummer
  \     /
   [SPL]
     |
 personnummer
\end{verbatim}

For simplicity the labels range over an entire connected
component in the graph.
\footnote{Should this level of granularity prove too restrictive
it can be lifted to allow labelling individual edges or tokens.}

By putting the labels on components of edges
(rather than the alternative to put them on the source tokens)
gives the advantage that any part of the interface
can be used to annotate the norm deviations:
the user may click words in the source text and choose
a norm deviation label from a menu. Or, they can click
on the graph directly. Or in any of the other two panes,
since they are all connected via the links.
Further, insertions (due to missing words) do not correspond to any token
in the source text so it would not work to only put labels on the
source text.

The norm deviation annotation can be done after normalising the text,
but we can go back and forth between the modes if the annotator want to
improve the normalisation.

A preliminary error annotation can be automatically inferred. This is
something that we plan to explore later on in the project.
Many deviation labels will be easy to infer even without any linguistic
insight, in particular: missing word, redundant word, word order, but also:
overcompounding, oversplitting.
Automatic label suggestion can be done independently of the rest of the user interface,
like a plugin, and adding more heuristics as the project continues.
For example, in a suffixing language like Swedish we could have heuristics
that detect if tense or determinancy has been transformed, and give
suggestions automatically for relevant labels.

For ergonomics, when using the tool for several hours a day,
we also provide keyboard bindings for labelling and navigating between
the linked components.

Note to reviewers: this is the scheduled to be completed in a few weeks
will be completed well before the camera-ready version.

Note that we can use the same system for anonymizing the text
by setting a special anonymization label. We (hope) that we can
then release a anonymized version of the corpus stripped out
of source tokens connected to such an anonymisation label.

Elena: Also something about about our intended error categories? Yes, I will add a bit on this

\section{Discussion}
\label{sec:discussion}

Summarise overall workflow\ldots ?

We believe that the following properties of our approach will contribute to more reliable normalisation, less time-consuming annotation and production of more valuable corpus resources compared to traditional methods (can we substantiate any of this?):

First, the conceptually different tasks of deciding on a target hypotheses (with resulting normalisations) and annotating norm deviations are separated. Also, since the source text and normalised text are displayed in separate panes, with the normalised text being incrementally updated, the annotator is provided with excellent facilities for getting to know the specific inter-language of the learner, and to make consistent decisions on target hypotheses. In addition, the editing operations could be used for inferring a preliminary error annotation, though this is a path that we have not yet explored. Furthermore, a parallel text is automatically constructed based on the editing operations, which provides a resource valuable for independent purposes, such as training of a system for automated normalisation.

The user experience will be improved by allowing the annotator to connect
and disconnect links directly in the ladder diagram. This should also be
possible by using keyboard shortcuts in the editor.  Frequent operations
such as transposing words can also get dedicated keyboard bindings.

...

The approach in general can be applied to other scenarios, where parallel versions and (documented?) differences between them are vital for developing automated tool for the purpose, e.g. text simplification, standardizing short message texts, essay-grading by teachers for personal or online (collaborative ?) feedback (teachers/peer reviewers suggesting better rewriting of a learner's text (e.g. Lo, Wang and Yeh (2008) and Yeh and Lo (2009) for their Online Annotator for EFL Writing say   “that online annotation functionalities for manipulating, rearranging, search, displaying and sharing annotations can be used to support EFL error correction and corrective feedback, especially the collaboration between teachers and students outside the classroom” (p. 883))...

...


\section{Conclusion}
\label{sec:conclusions}

Your submission of a finalised contribution for inclusion in the LREC
proceedings automatically assigns the above-mentioned copyright to ELRA.

\section{Acknowledgements}

This work has been supported by an infrastructure grant from Riksbankens Jubileumsfond (SweLL -- Research Infrastructure for Swedish as a Second Language, project IN16-0464:1). The design of the tool owes much to an earlier pilot developed by Felix Hultin \cite{correctAnnotator}, supervised by Robert Östling and Mats Wirén. We have received valuable comments and feedback on the tool from Markus Forsberg, Lars Borin and Beáta Megyesi.

\begin{comment}
\section{Providing References}

\subsection{Bibliographical References}
Bibliographical references should be listed in alphabetical order at the
end of the article. The title of the section, ``Bibliographical References'',
should be a level 1 heading. The first line of each bibliographical reference
should be justified to the left of the column, and the rest of the entry should
be indented by 0.35 cm.

The examples provided in Section \secref{main:ref} (some of which are fictitious
references) illustrate the basic format required for articles in conference
proceedings, books, journal articles, PhD theses, and chapters of books.

\subsection{Language Resource References}

Language resource references should be listed in alphabetical order at the end
of the article, in the \textbf{Language Resource References} section, placed after
the \textbf{Bibliographical References} section. The title of the ``Language Resource
References'' section, should be a level 1 heading. The first line of each
language resource reference should be justified to the left of the column, and
the rest of the entry should be indented by 0.35 cm. The example in Section
\secref{lr:ref} illustrates the basic format required for language resources.

In order to be able to cite a language resource, it must be added to
the \texttt{.bib} file first, as a \texttt{@LanguageResource} item type, which
contains the following fields:

\begin{itemize}
    \item{\texttt{author}: the builder of the resource}
    \item{\texttt{title}: the name of the resource}
    \item{\texttt{publisher}: the publisher of the resource (project,
          organisation etc)}
    \item{\texttt{year}: year of the resource release}
    \item{\texttt{series}: more general resource set this language resource
          belongs to}
    \item{\texttt{edition}: version of the resource}
    \item{\texttt{islrn}: the International Standard Language Resource Number
          (ISLRN) of the resource\footnote{The ISLRN number is available from
          \texttt{http://islrn.org}}}
\end{itemize}

If you want the full resource author name to appear in the citation, the
language resource author name should be protected by enclosing it between
\texttt{\{...\}}, as shown in the model \texttt{.bib} file.

\vspace{.3\baselineskip}

\section*{Appendix: How to Produce the \texttt{.pdf} Version}

In order to generate a PDF file out of the LaTeX file herein, when citing
language resources, the following steps need to be performed:

\begin{itemize}
    \item{Compile the \texttt{.tex} file once}
    \item{Invoke \texttt{bibtex} on the eponymous \texttt{.aux} file}
    \item{Invoke \texttt{bibtex} on the \texttt{languageresources.aux} file}
    \item{Compile the \texttt{.tex} file twice}
\end{itemize}
\end{comment}

% \nocite{*}
\section{Bibliographical References}
\label{main:ref}

\bibliographystyle{lrec}
\bibliography{xample}

% \section{Language Resource References}
% \label{lr:ref}
% \bibliographystylelanguageresource{lrec}
% \bibliographylanguageresource{xample}

\end{document}
